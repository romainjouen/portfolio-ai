# ğŸš€ Text to SQL and Python Analyzer

A comprehensive data analysis platform that combines AI-powered SQL generation and Python data analysis. The application connects to your PostgreSQL database, understands your schema, and provides intelligent query generation and data analysis capabilities using multiple AI providers.

## âœ¨ Features

- **ğŸ” SQL Generator**: Convert natural language to SQL queries with semantic understanding
- **ğŸ Python Data Agent**: Generate and execute Python code for data analysis and visualization
- **âš™ï¸ Multi-Provider Support**: Choose between OpenAI (GPT models) and Ollama (local models)
- **ğŸ›‘ Stop Controls**: Interrupt AI generation processes with stop buttons
- **ğŸ“Š Interactive UI**: Modern Streamlit interface with tabbed navigation
- **ğŸ’¾ Output Management**: Automatic saving of results and analysis
- **ğŸ”§ Configuration Management**: Flexible model and database configuration
- **ğŸ“ˆ Metadata Tracking**: Detailed performance and usage metrics

## ğŸ”§ Pre-requisites

### For Ollama (Local Models)
Install Ollama on your local machine from the [official website](https://ollama.com/) and pull the necessary models:

```bash
ollama pull qwen2.5-coder:32b
# Or other models you prefer
```

### For OpenAI (Cloud Models)
Get an OpenAI API key from [OpenAI Platform](https://platform.openai.com/) and set it as an environment variable.

## ğŸ Setup Python Environment

Create and activate a virtual environment:

```bash
# Create a virtual environment
python -m venv venv

# Activate the virtual environment
# On macOS and Linux
source venv/bin/activate
# On Windows
# venv\Scripts\activate
```

Install the dependencies:

```bash
pip install -r requirements.txt
```

## âš™ï¸ Configuration

### Environment Variables
Create a `.env` file in the project root:

```bash
# Database password (required)
DB_PASSWORD=your_database_password

# OpenAI API key (optional, only if using OpenAI models)
OPENAI_API_KEY=your_openai_api_key
```

### Configuration Files
The application uses two main configuration files in the `conf` directory:

#### 1. `conf/config.json` - Main Configuration
```json
{
    "postgres": {
        "host": "localhost",
        "dbname": "your_database",
        "user": "your_username",
        "port": "5432"
    },
    "models": {
        "openai": {
            "default": "gpt-4o-mini",
            "alternatives": ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"]
        },
        "ollama": {
            "default": "qwen2.5-coder:32b",
            "alternatives": ["llama3.1", "mistral", "codellama"]
        }
    },
    "temperature": 0.0
}
```

#### 2. `conf/data_analysis/semantic_model.json` - Database Schema Info
```json
{
    "tables": {
        "your_table": {
            "description": "Description of what this table contains",
            "columns": {
                "column_name": "Description of this column"
            }
        }
    },
    "relationships": [
        {
            "from_table": "table1",
            "to_table": "table2",
            "relationship": "foreign_key",
            "description": "How these tables are related"
        }
    ]
}
```

## ğŸš€ Usage

1. **Start the application**:
```bash
streamlit run app.py
```

2. **Configure your AI models** in the Configuration tab:
   - Select your preferred AI provider (OpenAI or Ollama)
   - Choose a specific model
   - Adjust temperature settings for creativity vs consistency

3. **Generate SQL queries** in the SQL Generator tab:
   - Describe what data you want in natural language
   - Review and edit the generated SQL
   - Execute queries and view results
   - Use the stop button to interrupt long generations

4. **Analyze data** in the Python Data Agent tab:
   - Work with data from your SQL queries
   - Request analysis, visualizations, or insights
   - Review and execute generated Python code
   - Stop generation if needed

## ğŸ“ Project Structure

```
data_analysis/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ .env                           # Environment variables (create this)
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ conf/                          # Configuration files
â”‚   â”œâ”€â”€ config.json               # Database & model configuration
â”‚   â””â”€â”€ data_analysis/
â”‚       â””â”€â”€ semantic_model.json   # Database schema information
â”œâ”€â”€ src/                          # Source code package
â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ data_analysis/           # Core analysis agents
â”‚   â”‚   â”œâ”€â”€ __init__.py         
â”‚   â”‚   â”œâ”€â”€ python_agent.py     # Python code generation agent
â”‚   â”‚   â”œâ”€â”€ python_agent_utils.py
â”‚   â”‚   â”œâ”€â”€ sql_agent.py        # SQL generation agent
â”‚   â”‚   â””â”€â”€ sql_agent_utils.py  
â”‚   â”œâ”€â”€ ui_components/           # User interface components
â”‚   â”‚   â””â”€â”€ ui.py               # Streamlit UI classes
â”‚   â””â”€â”€ utils/                   # Utility modules
â”‚       â”œâ”€â”€ __init__.py         
â”‚       â””â”€â”€ output_manager.py   # Result saving and management
â”œâ”€â”€ output/                      # Generated outputs and results
â””â”€â”€ venv/                       # Virtual environment (created by you)
```

## ğŸ¯ Key Features Explained

### Multi-Provider AI Support
- **OpenAI**: Cloud-based models like GPT-4o, GPT-4-turbo for high-quality results
- **Ollama**: Local models for privacy and cost control

### Stop Button Functionality
- Interrupt SQL generation or Python code generation at any time
- Prevents long-running or unwanted AI processes
- Maintains UI responsiveness during generation

### Intelligent SQL Generation
- Uses semantic model understanding of your database
- Considers table relationships and column meanings
- Generates optimized queries based on natural language input

### Advanced Python Analysis
- Generates context-aware Python code for data analysis
- Supports visualization, statistical analysis, and data manipulation
- Executes code safely with error handling

### Output Management
- Automatically saves all queries, generated code, and results
- Tracks metadata like execution time, token usage, and model performance
- Organizes outputs for easy retrieval and analysis

## ğŸ” Troubleshooting

### Database Connection Issues
- Ensure PostgreSQL is running and accessible
- Verify database credentials in `config.json` and `.env`
- Check firewall and network connectivity

### AI Model Issues
- For Ollama: Ensure Ollama is running (`ollama serve`)
- For OpenAI: Verify your API key is set correctly
- Check model availability and spelling in configuration

### Generation Issues
- Use stop buttons if generation takes too long
- Try different temperature settings for varied results
- Ensure semantic model accurately describes your database


## ğŸ¥ Demo

You can watch a demo video of an earlier version on [YouTube](https://youtu.be/kem-v9MXuG4).

## ğŸ¤ Contributing

Feel free to contribute by:
- Adding support for more AI providers
- Improving the semantic model understanding
- Enhancing the UI/UX
- Adding new analysis capabilities

## ğŸ“„ License

This project is open source. Please check the license file for details.